# NeoRAG: Advanced Retrieval-Augmented Generation System
Há»‡ thá»‘ng NeoRAG Ä‘Æ°á»£c thiáº¿t káº¿ vá»›i kiáº¿n trÃºc RAG tiÃªn tiáº¿n, tÃ­ch há»£p nhiá»u ká»¹ thuáº­t tá»‘i Æ°u hÃ³a Ä‘á»ƒ nÃ¢ng cao hiá»‡u suáº¥t retrieval vÃ  generation.

## ğŸ“Š SÆ¡ Ä‘á»“ kiáº¿n trÃºc

```mermaid
graph TD
    A[User Query]
    A --> B["Query Expansion
    â€¢ Synonym Expansion
    â€¢ Context-Aware Expansion"]
    B --> C["Embedding Model
    halobiron/bge-m3-embedding-PROPTIT-domain-ft
    (sentence-transformers)"]
    C --> D["Vector Database:
    ChromaDB"]
    D --> E[Retrieve Results]
    E --> F["Re-ranking
    halobiron/ViRanker-PROPTIT-domain-ft"]
    F --> G["Context Fusion & LLM Generation
    writer/palmyra-med-70b"]
    G --> H[Final Answer]
```  

## ğŸ¯ Giá»›i thiá»‡u vá» kiáº¿n trÃºc

**NeoRAG** lÃ  há»‡ thá»‘ng RAG (Retrieval-Augmented Generation) Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a Ä‘áº·c biá»‡t cho domain cÃ¢u láº¡c bá»™ láº­p trÃ¬nh ProPTIT. Há»‡ thá»‘ng káº¿t há»£p nhiá»u ká»¹ thuáº­t tiÃªn tiáº¿n:

### ğŸ”§ CÃ¡c thÃ nh pháº§n chÃ­nh:

1. **Query Expansion Module**: Má»Ÿ rá»™ng cÃ¢u truy váº¥n vá»›i 2 ká»¹ thuáº­t chÃ­nh
4. **ProPTIT-Optimized Embedding and Reranking**: 2 mÃ´ hÃ¬nh Ä‘Æ°á»£c fine-tune cho domain ProPTIT
5. **Optimized LLM Generation**: NVIDIA vá»›i prompts tá»‘i Æ°u cho domain ProPTITï¸

### ğŸš€ Ká»¹ thuáº­t Query Expansion:

- **Synonym Expansion**: Má»Ÿ rá»™ng vá»›i tá»« Ä‘á»“ng nghÄ©a vÃ  cÃ¡ch diá»…n Ä‘áº¡t khÃ¡c tá»« domain-specific keywords
- **Context-Aware Expansion**: Má»Ÿ rá»™ng dá»±a trÃªn ngá»¯ cáº£nh CLB ProPTIT vá»›i template-based patterns

## ğŸ“ˆ Benchmark Results

### ğŸ‹ï¸ Retrieval Metrics - Train Data (100 queries)

| Metric | k=3 | k=5 | k=7 |
|--------|-----|-----|-----|
| **Hit@k** | 0.95 | 0.99 | 0.99 |
| **Recall@k** | 0.85 | 0.94 | 0.95 |
| **Precision@k** | 0.55 | 0.37 | 0.27 |
| **F1@k** | 0.67 | 0.54 | 0.43 |
| **MAP@k** | 0.85 | 0.79 | 0.78 |
| **MRR@k** | 0.86 | 0.82 | 0.81 |
| **NDCG@k** | 0.88 | 0.85 | 0.84 |
| **Context Precision@k** | 0.90 | 0.66 | 0.66 |
| **Context Recall@k** | 0.68 | 0.56 | 0.54 |
| **Context Entities Recall@k** | 0.77 | 0.83 | 0.84 |

### ğŸ¤– LLM Answer Metrics - Train Data

| Metric | k=3 | k=5 | k=7 |
|--------|-----|-----|-----|
| **String Presence@k** | 0.73 | 0.74 | 0.73 |
| **ROUGE-L@k** | 0.25 | 0.26 | 0.24 |
| **BLEU-4@k** | 0.05 | 0.06 | 0.05 |
| **Groundedness@k** | 0.94 | 0.95 | 0.95 |
| **Response Relevancy@k** | 0.82 | 0.82 | 0.82 |
| **Noise Sensitivity@k** | 0.16 | 0.15 | 0.14 |

### ğŸ¯ Retrieval Metrics - Test Data (30 queries)

| Metric | k=3 | k=5 | k=7 |
|--------|-----|-----|-----|
| **Hit@k** | 0.97 | 0.97 | 0.97 |
| **Recall@k** | 0.82 | 0.89 | 0.91 |
| **Precision@k** | 0.53 | 0.37 | 0.28 |
| **F1@k** | 0.65 | 0.52 | 0.42 |
| **MAP@k** | 0.89 | 0.84 | 0.82 |
| **MRR@k** | 0.89 | 0.86 | 0.85 |
| **NDCG@k** | 0.91 | 0.88 | 0.87 |
| **Context Precision@k** | 0.96 | 0.75 | 0.78 |
| **Context Recall@k** | 0.93 | 0.69 | 0.72 |
| **Context Entities Recall@k** | 0.93 | 0.95 | 0.97 |

### ğŸ¤– LLM Answer Metrics - Test Data

| Metric | k=3 | k=5 | k=7 |
|--------|-----|-----|-----|
| **String Presence@k** | 0.85 | 0.85 | 0.85 |
| **ROUGE-L@k** | 0.58 | 0.58 | 0.57 |
| **BLEU-4@k** | 0.37 | 0.37 | 0.36 |
| **Groundedness@k** | 1.00 | 1.00 | 1.00 |
| **Response Relevancy@k** | 0.81 | 0.82 | 0.81 |
| **Noise Sensitivity@k** | 0.02 | 0.02 | 0.01 |

## âœ¨ Äiá»ƒm ná»•i báº­t (Äiá»ƒm máº¡nh)

### ğŸ”¥ Ká»¹ thuáº­t:
- **Domain-specific Query Expansion**: 3 ká»¹ thuáº­t má»Ÿ rá»™ng query vá»›i tá»« khÃ³a chuyÃªn biá»‡t cho CLB ProPTIT
- **Fine-tune Embedding & Reranking**: 2 mÃ´ hÃ¬nh Ä‘Æ°á»£c fine-tune sao cho phÃ¹ há»£p vá»›i domain PROPTIT
- **Hybrid Retrieval Pipeline**: Káº¿t há»£p retrieval ban Ä‘áº§u + reranking vá»›i scoring tá»‘i Æ°u

### ğŸŒŸ Hiá»‡u suáº¥t vÆ°á»£t trá»™i:
- Hiá»‡u suáº¥t retrieval & generation á»•n Ä‘á»‹nh trÃªn cáº£ táº­p train vÃ  test vá»›i 15+ metrics
- Äá»™ groundedness vÃ  relevancy cao (groundedness@3 Ä‘áº¡t 1.0 trÃªn test)

### ğŸ‡»ğŸ‡³ Tá»‘i Æ°u tiáº¿ng Viá»‡t:
- **Domain-Specific Keywords**: Bá»™ tá»« khÃ³a chuyÃªn biá»‡t cho lÄ©nh vá»±c giÃ¡o dá»¥c vÃ  CLB ProPTIT
- **Context-Aware Expansion**: Hiá»ƒu ngá»¯ cáº£nh vÄƒn hÃ³a vÃ  thuáº­t ngá»¯ Viá»‡t Nam
- **Optimized Prompts**: Prompts Ä‘Æ°á»£c thiáº¿t káº¿ phÃ¹ há»£p vá»›i phong cÃ¡ch giao tiáº¿p tiáº¿ng Viá»‡t

## âš ï¸ Háº¡n cháº¿

### ğŸŒ Hiá»‡u suáº¥t:
 - **Äá»™ trá»… cao**: YÃªu cáº§u GPU cho latency tháº¥p; CPU Ä‘Æ¡n láº» cÃ³ thá»ƒ cháº­m

### ğŸ¯ Äá»™ chÃ­nh xÃ¡c:
- **Domain Dependency**: Hiá»‡u suáº¥t giáº£m khi Ã¡p dá»¥ng cho domain khÃ¡c ngoÃ i ProPTIT

### ğŸ”§ Ká»¹ thuáº­t:
- **Model Dependency**: Phá»¥ thuá»™c vÃ o cháº¥t lÆ°á»£ng cá»§a external models (BAAI, ViRanker)
- **Debugging Complexity**: Kiáº¿n trÃºc phá»©c táº¡p lÃ m khÃ³ debug vÃ  maintain

### ğŸ“Š Evaluation:
- **Subjective evaluation**: Thiáº¿u Ä‘Ã¡nh giÃ¡ human evaluation

## ğŸ› ï¸ Technical Stack

### ğŸ“¦ Core Dependencies:
- **Embedding**: `sentence-transformers`, `BAAI/bge-m3`, `FlagEmbedding`
- **Vector DB**: `chromadb`, `qdrant-client`, `pymongo` (Multi-database support)
- **Reranking**: `FlagEmbedding`, `namdp-ptit/ViRanker` (Vietnamese-optimized)
- **LLM Integration**: `requests` (NVIDIA API)
- **Query Expansion**: Custom implementation vá»›i domain-specific keywords
- **Metrics**: Comprehensive evaluation vá»›i 15+ metrics
- **Document Processing**: `python-docx`, `pandas`, `numpy`