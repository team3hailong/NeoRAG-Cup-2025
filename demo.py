import streamlit as st
import pandas as pd
import numpy as np
import json
import time
from docx import Document
import plotly.express as px
import plotly.graph_objects as go
from embeddings import Embeddings
from vector_db import VectorDatabase
from rerank import Reranker
from metrics_rag import (
    calculate_metrics_retrieval, 
    calculate_metrics_llm_answer,
    hit_k, recall_k, precision_k, context_precision_k, 
    context_recall_k, context_entities_recall_k, ndcg_k,
    retrieve_and_rerank
)
from groq import Groq
import os
from dotenv import load_dotenv

load_dotenv()

# Page config
st.set_page_config(
    page_title="NeoRAG Cup 2025 - Demo",
    page_icon="üöÄ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #ff6b6b;
        margin: 0.5rem 0;
    }
    .chat-message {
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .user-message {
        background-color: #e3f2fd;
        border-left: 4px solid #2196f3;
    }
    .assistant-message {
        background-color: #ffffff;
        padding: 1rem;
        border-radius: 0.75rem;
        border-left: 4px solid #9c27b0;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        color: #333333;
        font-family: "Segoe UI", Tahoma, Geneva, Verdana, sans-serif;
        transition: background-color 0.3s ease;
    }
    .assistant-message:hover {
        background-color: #f5f0f8;
    }
    .sidebar .sidebar-content {
        background-color: #f8f9fa;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
    }
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        padding-left: 20px;
        padding-right: 20px;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'vector_db' not in st.session_state:
    st.session_state.vector_db = None
if 'embedding_model' not in st.session_state:
    st.session_state.embedding_model = None
if 'reranker' not in st.session_state:
    st.session_state.reranker = None
if 'initialized' not in st.session_state:
    st.session_state.initialized = False

# Header
st.title("üöÄ NeoRAG Cup 2025 - Demo System")
st.markdown("---")

# Sidebar Configuration
with st.sidebar:
    st.header("‚öôÔ∏è C·∫•u h√¨nh h·ªá th·ªëng")
    
    # Default optimal configuration
    st.info("üéØ **C·∫•u h√¨nh t·ªëi ∆∞u m·∫∑c ƒë·ªãnh:** ChromaDB + BGE-M3 + ViRanker + Query Expansion")
    
    # Main Configuration
    st.markdown("### üìä Vector Database")
    db_type = st.radio(
        "Ch·ªçn database:",
        ["chromadb", "mongodb", "qdrant", "supabase"],
        index=0,
        horizontal=True
    )
    
    st.markdown("### üß† Embedding Model")
    col1, col2 = st.columns([1, 1])
    with col1:
        embedding_type = st.selectbox(
            "Lo·∫°i model:",
            ["sentence_transformers", "openai", "gemini", "ollama"],
            index=0
        )
    
    with col2:
        if embedding_type == "sentence_transformers":
            model_name = st.selectbox(
                "Model:",
                ["BAAI/bge-m3", "Alibaba-NLP/gte-multilingual-base", "sentence-transformers/all-MiniLM-L6-v2"],
                index=0
            )
        elif embedding_type == "openai":
            model_name = st.selectbox(
                "Model:",
                ["text-embedding-3-large", "text-embedding-3-small", "text-embedding-ada-002"],
                index=0
            )
        else:
            model_name = st.text_input("Model:", "BAAI/bge-m3")
    
    st.markdown("### üîÑ Retrieval Options")
    col1, col2 = st.columns([1, 1])
    with col1:
        use_reranker = st.checkbox("üîÑ Reranker", value=True)
        use_query_expansion = st.checkbox("üîç Query Expansion", value=True)
    
    with col2:
        if use_reranker:
            reranker_model = st.selectbox(
                "Reranker:",
                ["namdp-ptit/ViRanker", "BAAI/bge-reranker-v2-m3"],
                index=0
            )
    
    # LLM Configuration
    st.markdown("### ü§ñ LLM Configuration")
    llm_model = st.selectbox(
        "LLM Model:",
        [
            "meta-llama/llama-4-maverick-17b-128e-instruct",
            "llama-3.3-70b-versatile",
            "llama3-70b-8192", 
            "llama-3.1-8b-instant",
            "gemma2-9b-it",
            "qwen/qwen3-32b",
            "meta-llama/llama-4-scout-17b-16e-instruct",
            "allam-2-7b",
            "moonshotai/kimi-k2-instruct",
            "compound-beta",
            "deepseek-r1-distill-llama-70b"
        ],
        index=0
    )
    
    # Advanced LLM settings
    with st.expander("üîß Tham s·ªë LLM", expanded=False):
        col1, col2 = st.columns(2)
        with col1:
            max_tokens = st.slider("Max Tokens", 256, 2048, 1024, 128)
        with col2:
            temperature = st.slider("Temperature", 0.0, 1.0, 0.4, 0.1)
    
    # Status indicators
    st.markdown("### üìä Tr·∫°ng th√°i h·ªá th·ªëng")
    if st.session_state.initialized:
        st.success("‚úÖ H·ªá th·ªëng ƒë√£ s·∫µn s√†ng")
        if st.session_state.vector_db:
            try:
                doc_count = st.session_state.vector_db.count_documents("information")
                st.info(f"üìö {doc_count} documents ƒë√£ ƒë∆∞·ª£c load")
            except:
                pass
    else:
        st.warning("‚ö†Ô∏è Ch∆∞a kh·ªüi t·∫°o")
    
    # Initialize system button
    init_col1, init_col2 = st.columns([2, 1])
    with init_col1:
        if st.button("üîß Kh·ªüi t·∫°o h·ªá th·ªëng", type="primary", use_container_width=True):
            with st.spinner("ƒêang kh·ªüi t·∫°o h·ªá th·ªëng..."):
                try:
                    # Initialize vector database
                    st.session_state.vector_db = VectorDatabase(db_type=db_type)
                    
                    # Initialize embedding model
                    st.session_state.embedding_model = Embeddings(
                        model_name=model_name,
                        type=embedding_type
                    )
                    
                    # Initialize reranker if needed
                    if use_reranker:
                        st.session_state.reranker = Reranker(model_name=reranker_model)
                    else:
                        st.session_state.reranker = None
                    
                    # Load documents if not already loaded
                    if st.session_state.vector_db.count_documents("information") == 0:
                        doc = Document("CLB_PROPTIT.docx")
                        cnt = 1
                        progress_bar = st.progress(0)
                        total_paras = len([p for p in doc.paragraphs if p.text.strip()])
                        
                        for i, para in enumerate(doc.paragraphs):
                            if para.text.strip():
                                embedding_vector = st.session_state.embedding_model.encode(para.text)
                                st.session_state.vector_db.insert_document(
                                    collection_name="information",
                                    document={
                                        "title": f"Document {cnt}",
                                        "information": para.text,
                                        "embedding": embedding_vector
                                    }
                                )
                                cnt += 1
                                progress_bar.progress((i + 1) / total_paras)
                        
                        st.success(f"ƒê√£ load {cnt-1} documents v√†o database!")
                    else:
                        st.info("Documents ƒë√£ t·ªìn t·∫°i trong database.")
                    
                    st.session_state.initialized = True
                    st.success("H·ªá th·ªëng ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng!")
                    st.rerun()  # Refresh to update status
                    
                except Exception as e:
                    st.error(f"L·ªói khi kh·ªüi t·∫°o h·ªá th·ªëng: {str(e)}")
    
    with init_col2:
        if st.session_state.initialized:
            if st.button("üîÑ", help="Reset h·ªá th·ªëng"):
                st.session_state.initialized = False
                st.session_state.vector_db = None
                st.session_state.embedding_model = None
                st.session_state.reranker = None
                st.rerun()

# Main content tabs
tab1, tab2, tab3, tab4 = st.tabs(["üí¨ Chat Demo", "üìä Metrics", "üìà Performance", "üìÑ Dataset Info"])

with tab1:
    st.header("üí¨ Chat v·ªõi h·ªá th·ªëng RAG")
    
    if not st.session_state.initialized:
        st.warning("‚ö†Ô∏è Vui l√≤ng kh·ªüi t·∫°o h·ªá th·ªëng ·ªü sidebar tr∆∞·ªõc khi s·ª≠ d·ª•ng!")
    else:
        # Chat configuration
        col1, col2, col3 = st.columns([2, 1, 1])
        
        with col1:
            user_query = st.text_input(
                "H·ªèi v·ªÅ CLB ProPTIT:",
                placeholder="V√≠ d·ª•: CLB ProPTIT ƒë∆∞·ª£c th√†nh l·∫≠p khi n√†o?",
                key="user_input"
            )
        
        with col2:
            top_k = st.selectbox("Top K", [3, 5, 7, 10], index=1)
        
        with col3:
            ask_button = st.button("üöÄ H·ªèi", type="primary")
        
        if ask_button and user_query:
            with st.spinner("ƒêang t√¨m ki·∫øm v√† t·∫°o c√¢u tr·∫£ l·ªùi..."):
                try:
                    # Retrieve relevant documents
                    start_time = time.time()
                    
                    results = retrieve_and_rerank(
                        query=user_query,
                        embedding=st.session_state.embedding_model,
                        vector_db=st.session_state.vector_db,
                        reranker=st.session_state.reranker,
                        k=top_k,
                        use_query_expansion=use_query_expansion
                    )
                    
                    retrieval_time = time.time() - start_time
                    
                    # Display retrieved documents
                    st.subheader("üìã Documents ƒë∆∞·ª£c truy xu·∫•t:")
                    for i, doc in enumerate(results[:3]):  # Show top 3
                        with st.expander(f"Document {i+1}: {doc.get('title', 'N/A')}"):
                            st.write(doc.get('information', 'N/A'))
                            if 'score' in doc:
                                st.write(f"**Score:** {doc['score']:.4f}")
                    
                    # Generate answer using Groq (if API key available)
                    context = "\n\n".join([doc.get('information', '') for doc in results])
                    
                    if os.getenv("GROQ_API_KEY"):
                        client = Groq(api_key=os.getenv("GROQ_API_KEY"))
                        
                        prompt = f"""
                        **B·ªëi c·∫£nh:**
                        B·∫°n l√† m·ªôt tr·ª£ l√Ω AI chuy√™n gia v·ªÅ C√¢u l·∫°c b·ªô L·∫≠p tr√¨nh ProPTIT. Nhi·ªám v·ª• c·ªßa b·∫°n l√† cung c·∫•p c√°c c√¢u tr·∫£ l·ªùi ch√≠nh x√°c v√† h·ªØu √≠ch d·ª±a *duy nh·∫•t* v√†o th√¥ng tin ƒë∆∞·ª£c cung c·∫•p.

                        **V√≠ d·ª• (Few-shot Examples):**

                        *   **V√≠ d·ª• 1: Tr·∫£ l·ªùi v·ªÅ team d·ª± √°n**
                            *   **C√¢u h·ªèi:** "CLB c√≥ m·∫•y team d·ª± √°n ·∫°?"
                            *   **C√¢u tr·∫£ l·ªùi:** "Hi·ªán t·∫°i CLB ProPTIT c√≥ 6 team d·ª± √°n: Team AI, Team Mobile, Team Data, Team Game, Team Web, Team Backend. C√°c em s·∫Ω v√†o team d·ª± √°n sau khi ƒë√£ ho√†n th√†nh kh√≥a h·ªçc Java."

                        *   **V√≠ d·ª• 2: Tr·∫£ l·ªùi v·ªÅ quy tr√¨nh tuy·ªÉn th√†nh vi√™n**
                            *   **C√¢u h·ªèi:** "CLB tuy·ªÉn th√†nh vi√™n nh∆∞ th·∫ø n√†o ·∫°?"
                            *   **C√¢u tr·∫£ l·ªùi:** "Qu√° tr√¨nh tuy·ªÉn th√†nh vi√™n c·ªßa CLB g·ªìm 3 v√≤ng: ƒë·∫ßu ti√™n l√† v√≤ng CV, sau ƒë√≥ s·∫Ω ƒë·∫øn v√≤ng Ph·ªèng v·∫•n v√† cu·ªëi c√πng l√† v√≤ng Training c·ªßa CLB. Th√¥ng tin chi ti·∫øt c·ªßa c√°c v√≤ng s·∫Ω ƒë∆∞·ª£c CLB c·∫≠p nh·∫≠t tr√™n fanpage."

                        *   **V√≠ d·ª• 3: Th√¥ng tin kh√¥ng c√≥ trong ng·ªØ c·∫£nh**
                            *   **C√¢u h·ªèi:** "CLB c√≥ bao nhi√™u th√†nh vi√™n hi·ªán t·∫°i?"
                            *   **C√¢u tr·∫£ l·ªùi:** "Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin v·ªÅ s·ªë l∆∞·ª£ng th√†nh vi√™n hi·ªán t·∫°i c·ªßa CLB trong t√†i li·ªáu ƒë∆∞·ª£c cung c·∫•p."

                        **Th√¥ng tin tham kh·∫£o:**
                        ---
                        {context}
                        ---

                        **Y√™u c·∫ßu:**
                        D·ª±a v√†o **duy nh·∫•t** "Th√¥ng tin tham kh·∫£o" ·ªü tr√™n v√† h·ªçc theo phong c√°ch t·ª´ c√°c v√≠ d·ª•, h√£y tr·∫£ l·ªùi c√¢u h·ªèi sau ƒë√¢y c·ªßa ng∆∞·ªùi d√πng.

                        **C√¢u h·ªèi:** "{user_query}"

                        **Quy t·∫Øc tr·∫£ l·ªùi:**
                        1.  **Ch√≠nh x√°c v√† Trung th·ª±c:** Ch·ªâ s·ª≠ d·ª•ng th√¥ng tin ƒë√£ cho. N·∫øu th√¥ng tin kh√¥ng c√≥ trong t√†i li·ªáu, h√£y tr·∫£ l·ªùi nh∆∞ "V√≠ d·ª• 2".
                        2.  **Chi ti·∫øt v√† R√µ r√†ng:** Tr·∫£ l·ªùi ƒë·∫ßy ƒë·ªß, chi ti·∫øt. S·ª≠ d·ª•ng g·∫°ch ƒë·∫ßu d√≤ng ho·∫∑c ƒë·ªãnh d·∫°ng ph√π h·ª£p n·∫øu c√¢u tr·∫£ l·ªùi c√≥ nhi·ªÅu √Ω ho·∫∑c c·∫ßn li·ªát k√™.
                        3.  **T·ª± nhi√™n v√† Th√¢n thi·ªán:** S·ª≠ d·ª•ng ng√¥n ng·ªØ ti·∫øng Vi·ªát t·ª± nhi√™n, gi·ªçng vƒÉn th√¢n thi·ªán nh∆∞ ƒëang tr√≤ chuy·ªán.
                        4.  **Kh√¥ng suy di·ªÖn:** Tuy·ªát ƒë·ªëi kh√¥ng suy di·ªÖn, kh√¥ng b·ªãa ƒë·∫∑t ho·∫∑c th√™m th√¥ng tin kh√¥ng c√≥ trong vƒÉn b·∫£n.

                        **C√¢u tr·∫£ l·ªùi c·ªßa b·∫°n (b·∫±ng ti·∫øng Vi·ªát):**
                        """
                        
                        response = client.chat.completions.create(
                            model=llm_model,
                            messages=[
                                {"role": "system", "content": "B·∫°n l√† m·ªôt tr·ª£ l√Ω AI chuy√™n gia v·ªÅ CLB L·∫≠p tr√¨nh ProPTIT, lu√¥n tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát d·ª±a tr√™n th√¥ng tin ƒë∆∞·ª£c cung c·∫•p."},
                                {"role": "user", "content": prompt}
                            ],
                            max_tokens=max_tokens,
                            temperature=temperature
                        )
                        
                        answer = response.choices[0].message.content
                    else:
                        answer = f"D·ª±a v√†o th√¥ng tin ƒë∆∞·ª£c truy xu·∫•t, ƒë√¢y l√† nh·ªØng th√¥ng tin li√™n quan ƒë·∫øn c√¢u h·ªèi '{user_query}':\n\n{context[:500]}...\n\n(L∆∞u √Ω: Vui l√≤ng c·∫•u h√¨nh GROQ_API_KEY ƒë·ªÉ s·ª≠ d·ª•ng LLM)"
                    
                    # Add to chat history
                    st.session_state.chat_history.append({
                        "query": user_query,
                        "answer": answer,
                        "retrieval_time": retrieval_time,
                        "num_docs": len(results)
                    })
                    
                    # Display answer
                    st.subheader("ü§ñ C√¢u tr·∫£ l·ªùi:")
                    st.markdown(f'<div class="assistant-message">{answer}</div>', unsafe_allow_html=True)
                    
                    # Display metrics
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("‚è±Ô∏è Th·ªùi gian retrieval", f"{retrieval_time:.2f}s")
                    with col2:
                        st.metric("üìä S·ªë documents", len(results))
                    with col3:
                        st.metric("üîç Top K", top_k)
                    with col4:
                        st.metric("ü§ñ Model", llm_model.split('/')[-1][:15] + "...")
                        
                except Exception as e:
                    st.error(f"L·ªói khi x·ª≠ l√Ω c√¢u h·ªèi: {str(e)}")
        
        # Display chat history
        if st.session_state.chat_history:
            st.subheader("üìú L·ªãch s·ª≠ chat")
            for i, chat in enumerate(reversed(st.session_state.chat_history[-5:])):  # Show last 5
                with st.expander(f"Q{len(st.session_state.chat_history)-i}: {chat['query'][:50]}..."):
                    st.markdown(f"**C√¢u h·ªèi:** {chat['query']}")
                    st.markdown(f"**Tr·∫£ l·ªùi:** {chat['answer']}")
                    st.markdown(f"**Th·ªùi gian:** {chat['retrieval_time']:.2f}s | **Docs:** {chat['num_docs']}")

with tab2:
    st.header("üìä Metrics Evaluation")
    
    if not st.session_state.initialized:
        st.warning("‚ö†Ô∏è Vui l√≤ng kh·ªüi t·∫°o h·ªá th·ªëng tr∆∞·ªõc!")
    else:
        col1, col2 = st.columns(2)
        
        with col1:
            eval_type = st.selectbox("Lo·∫°i ƒë√°nh gi√°", ["Retrieval Metrics", "LLM Answer Metrics"])
        
        with col2:
            dataset_type = st.selectbox("Dataset", ["Train", "Test"])
        
        if st.button("üßÆ T√≠nh to√°n Metrics"):
            with st.spinner("ƒêang t√≠nh to√°n metrics..."):
                try:
                    is_train = dataset_type == "Train"
                    
                    if eval_type == "Retrieval Metrics":
                        df_metrics = calculate_metrics_retrieval(
                            "CLB_PROPTIT.csv",
                            "train_data_proptit.xlsx",
                            st.session_state.embedding_model,
                            st.session_state.vector_db,
                            is_train
                        )
                        
                        st.subheader("üìà Retrieval Metrics Results")
                        st.dataframe(df_metrics)
                        
                        # Visualize metrics
                        if not df_metrics.empty:
                            fig = px.line(
                                df_metrics, 
                                x='k', 
                                y=['hit@k', 'recall@k', 'precision@k', 'f1@k'],
                                title="Retrieval Metrics vs K"
                            )
                            st.plotly_chart(fig, use_container_width=True)
                    
                    else:  # LLM Answer Metrics
                        df_metrics = calculate_metrics_llm_answer(
                            "CLB_PROPTIT.csv",
                            "train_data_proptit.xlsx",
                            st.session_state.embedding_model,
                            st.session_state.vector_db,
                            is_train,
                            st.session_state.reranker
                        )
                        
                        st.subheader("ü§ñ LLM Answer Metrics Results")
                        st.dataframe(df_metrics)
                        
                        # Visualize metrics
                        if not df_metrics.empty:
                            fig = px.line(
                                df_metrics,
                                x='k',
                                y=['string_presence@k', 'rouge_l@k', 'bleu_4@k', 'groundedness@k'],
                                title="LLM Answer Metrics vs K"
                            )
                            st.plotly_chart(fig, use_container_width=True)
                            
                except Exception as e:
                    st.error(f"L·ªói khi t√≠nh to√°n metrics: {str(e)}")

with tab3:
    st.header("üìà Performance Analysis")
    
    # Baseline comparison
    st.subheader("üéØ So s√°nh v·ªõi Baseline")
    
    # Create baseline data from the instructions
    baseline_retrieval_train = {
        'k': [3, 5, 7],
        'hit@k': [0.59, 0.57, 0.76],
        'recall@k': [0.41, 0.49, 0.54],
        'precision@k': [0.21, 0.16, 0.13],
        'f1@k': [0.28, 0.25, 0.21],
        'map@k': [0.52, 0.55, 0.54],
        'mrr@k': [0.52, 0.55, 0.56],
        'ndcg@k': [0.54, 0.59, 0.6],
        'context_precision@k': [0.78, 0.66, 0.57],
        'context_recall@k': [0.54, 0.45, 0.42],
        'context_entities_recall@k': [0.47, 0.45, 0.47]
    }
    
    baseline_llm_train = {
        'k': [3, 5, 7],
        'string_presence@k': [0.47, 0.50, 0.48],
        'rouge_l@k': [0.21, 0.23, 0.22],
        'bleu_4@k': [0.03, 0.03, 0.04],
        'groundedness@k': [0.57, 0.61, 0.64],
        'response_relevancy@k': [0.80, 0.80, 0.80],
        'noise_sensitivity@k': [0.51, 0.53, 0.51]
    }

    baseline_retrieval_test = {
        'k': [3, 5, 7],
        'hit@k': [0.93, 0.93, 0.97],
        'recall@k': [0.73, 0.76, 0.82],
        'precision@k': [0.47, 0.3, 0.24],
        'f1@k': [0.57, 0.43, 0.37],
        'map@k': [0.86, 0.84, 0.85],
        'mrr@k': [0.87, 0.87, 0.89],
        'ndcg@k': [0.88, 0.87, 0.89],
        'context_precision@k': [0.88, 0.74, 0.57],
        'context_recall@k': [0.66, 0.53, 0.45],
        'context_entities_recall@k': [0.61, 0.62, 0.67]
    }

    baseline_llm_test = {
        'k': [3, 5, 7],
        'string_presence@k': [0.53, 0.58, 0.57],
        'rouge_l@k': [0.21, 0.23, 0.22],
        'bleu_4@k': [0.03, 0.03, 0.04],
        'groundedness@k': [0.57, 0.61, 0.64],
        'response_relevancy@k': [0.80, 0.80, 0.80],
        'noise_sensitivity@k': [0.51, 0.53, 0.51]
    }
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üîç Baseline Retrieval Metrics (Train)")
        df_baseline_ret = pd.DataFrame(baseline_retrieval_train)
        st.dataframe(df_baseline_ret)
        
        # Plot baseline retrieval
        fig = go.Figure()
        metrics_to_plot = ['hit@k', 'recall@k', 'precision@k', 'ndcg@k']
        for metric in metrics_to_plot:
            fig.add_trace(go.Scatter(
                x=df_baseline_ret['k'],
                y=df_baseline_ret[metric],
                mode='lines+markers',
                name=metric
            ))
        fig.update_layout(title="Baseline Retrieval Metrics", xaxis_title="K", yaxis_title="Score")
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.subheader("ü§ñ Baseline LLM Metrics (Train)")
        df_baseline_llm = pd.DataFrame(baseline_llm_train)
        st.dataframe(df_baseline_llm)
        
        # Plot baseline LLM
        fig = go.Figure()
        metrics_to_plot = ['string_presence@k', 'rouge_l@k', 'groundedness@k', 'response_relevancy@k']
        for metric in metrics_to_plot:
            fig.add_trace(go.Scatter(
                x=df_baseline_llm['k'],
                y=df_baseline_llm[metric],
                mode='lines+markers',
                name=metric
            ))
        fig.update_layout(title="Baseline LLM Metrics", xaxis_title="K", yaxis_title="Score")
        st.plotly_chart(fig, use_container_width=True)
    
    # Individual metric testing
    if st.session_state.initialized:
        st.subheader("üî¨ Test Individual Metrics")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            test_k = st.slider("K value", 1, 10, 5)
        with col2:
            metric_type = st.selectbox("Metric", [
                "hit_k", "recall_k", "precision_k", "context_precision_k", 
                "context_recall_k", "context_entities_recall_k", "ndcg_k"
            ])
        with col3:
            test_expansion = st.checkbox("Use Query Expansion", value=True)
        
        if st.button("üß™ Test Metric"):
            with st.spinner(f"Testing {metric_type}@{test_k}..."):
                try:
                    if metric_type == "hit_k":
                        result = hit_k("CLB_PROPTIT.csv", "train_data_proptit.xlsx", 
                                     st.session_state.embedding_model, st.session_state.vector_db, 
                                     k=test_k, reranker=st.session_state.reranker, 
                                     use_query_expansion=test_expansion)
                    elif metric_type == "recall_k":
                        result = recall_k("CLB_PROPTIT.csv", "train_data_proptit.xlsx", 
                                        st.session_state.embedding_model, st.session_state.vector_db, 
                                        k=test_k, reranker=st.session_state.reranker, 
                                        use_query_expansion=test_expansion)
                    elif metric_type == "precision_k":
                        result = precision_k("CLB_PROPTIT.csv", "train_data_proptit.xlsx", 
                                           st.session_state.embedding_model, st.session_state.vector_db, 
                                           k=test_k, reranker=st.session_state.reranker, 
                                           use_query_expansion=test_expansion)
                    elif metric_type == "ndcg_k":
                        result = ndcg_k("CLB_PROPTIT.csv", "train_data_proptit.xlsx", 
                                      st.session_state.embedding_model, st.session_state.vector_db, 
                                      k=test_k, reranker=st.session_state.reranker, 
                                      use_query_expansion=test_expansion)
                    
                    st.success(f"**{metric_type}@{test_k}:** {result:.4f}")
                    
                    # Compare with baseline if available
                    if test_k in [3, 5, 7] and metric_type.replace('_', '@') in baseline_retrieval_train:
                        baseline_val = baseline_retrieval_train[metric_type.replace('_', '@')][baseline_retrieval_train['k'].index(test_k)]
                        improvement = ((result - baseline_val) / baseline_val) * 100
                        
                        if improvement > 0:
                            st.success(f"üéâ C·∫£i thi·ªán {improvement:.2f}% so v·ªõi baseline!")
                        else:
                            st.warning(f"üìâ Th·∫•p h∆°n baseline {abs(improvement):.2f}%")
                            
                except Exception as e:
                    st.error(f"L·ªói khi test metric: {str(e)}")

with tab4:
    st.header("üìÑ Dataset Information")
    
    # Dataset overview
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìä Document Statistics")
        try:
            doc = Document("CLB_PROPTIT.docx")
            total_paragraphs = len([p for p in doc.paragraphs if p.text.strip()])
            total_chars = sum(len(p.text) for p in doc.paragraphs if p.text.strip())
            avg_para_length = total_chars / total_paragraphs if total_paragraphs > 0 else 0
            
            st.metric("üìù T·ªïng paragraphs", total_paragraphs)
            st.metric("üî§ T·ªïng k√Ω t·ª±", f"{total_chars:,}")
            st.metric("üìè ƒê·ªô d√†i trung b√¨nh", f"{avg_para_length:.0f} chars")
            
        except Exception as e:
            st.error(f"Kh√¥ng th·ªÉ ƒë·ªçc file DOCX: {str(e)}")
    
    with col2:
        st.subheader("üéØ Query Statistics")
        try:
            df_train = pd.read_excel("train_data_proptit.xlsx")
            st.metric("‚ùì T·ªïng queries (train)", len(df_train))
            
            if 'question' in df_train.columns:
                avg_query_length = df_train['question'].str.len().mean()
                st.metric("üìè ƒê·ªô d√†i query TB", f"{avg_query_length:.0f} chars")
            
        except Exception as e:
            st.error(f"Kh√¥ng th·ªÉ ƒë·ªçc file train data: {str(e)}")
    
        # Database status
        if st.session_state.initialized and st.session_state.vector_db:
            st.subheader("üíæ Database Status")
            try:
                doc_count = st.session_state.vector_db.count_documents("information")
                status = ( "‚úÖ S·∫µn s√†ng"
                    if doc_count > 0 else
                    "‚ö†Ô∏è Tr·ªëng"
                )
                st.metric(f"üìö Documents in DB | {status}", f"{doc_count}")
            except Exception as e:
                st.error(f"L·ªói khi ki·ªÉm tra database: {str(e)}")

# Footer
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666666;'>
    <p>üöÄ <b>NeoRAG Cup 2025</b> - Powered by H·∫£i Long</p>
    <p>Built with ‚ù§Ô∏è using Streamlit</p>
</div>
""", unsafe_allow_html=True)
