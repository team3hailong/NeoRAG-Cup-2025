# ğŸ¯ HÆ°á»›ng Dáº«n Fine-tune ToÃ n Diá»‡n cho NeoRAG Cup 2025

## ğŸ“‹ Má»¥c Lá»¥c
1. [Giá»›i thiá»‡u](#giá»›i-thiá»‡u)
2. [Fine-tune Embedding Model (BGE-M3)](#fine-tune-embedding-model-bge-m3)
3. [Fine-tune Reranker](#fine-tune-reranker)
4. [Tá»‘i Æ°u hÃ³a vÃ  Troubleshooting](#tá»‘i-Æ°u-hÃ³a-vÃ -troubleshooting)
5. [Best Practices](#best-practices)

---

## ğŸ“ Giá»›i thiá»‡u

Fine-tuning lÃ  bÆ°á»›c quan trá»ng Ä‘á»ƒ tá»‘i Æ°u hÃ³a RAG system cho domain cá»¥ thá»ƒ cá»§a CLB ProPTIT. Trong NeoRAG Cup 2025, viá»‡c fine-tune cáº£ embedding model vÃ  reranker giÃºp cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ cÃ¡c metrics benchmark nhÆ° context_recall, context_precision, vÃ  response_relevancy.

### Quy trÃ¬nh Fine-tune
1. Chuáº©n bá»‹ dá»¯ liá»‡u (train/dev sets)
2. Cáº¥u hÃ¬nh hyperparameters tá»‘i Æ°u
3. Training vá»›i monitoring
4. Evaluation vÃ  iteration

### Hyperparameters ChÃ­nh

*LÆ°u Ã½: CÃ¡c template dÆ°á»›i Ä‘Ã¢y Ä‘Ã£ chá»‰ Ä‘á»‹nh giÃ¡ trá»‹ tá»‘i Æ°u cá»¥ thá»ƒ cho tá»«ng model. Báº£ng nÃ y chá»‰ hÆ°á»›ng dáº«n Ä‘iá»u chá»‰nh náº¿u Ä‘iá»ƒm sá»‘ benchmark tháº¥p (tuyáº¿n tÃ­nh).*

| Tham sá»‘/Model | HÆ°á»›ng Ä‘iá»u chá»‰nh (náº¿u Ä‘iá»ƒm sá»‘ tháº¥p) |
|---------------|-------------------------------------|
| `epochs` | TÄƒng Ä‘á»ƒ convergence tá»‘t hÆ¡n |
| `batch_size` | Giáº£m náº¿u OOM, tÄƒng náº¿u gradients unstable |
| `max_seq_length` | Giá»¯ nguyÃªn (cá»‘ Ä‘á»‹nh) |
| `learning_rate` | Giáº£m náº¿u khÃ´ng convergence, tÄƒng nháº¹ náº¿u quÃ¡ cháº­m |
| `gradient_accumulation_steps` | TÄƒng Ä‘á»ƒ effective batch lá»›n hÆ¡n |
| `freeze_layers` | Giáº£m Ä‘á»ƒ há»c nhiá»u hÆ¡n (chá»‰ cho embedding) |
| `num_hard_negatives` | TÄƒng Ä‘á»ƒ discrimination tá»‘t hÆ¡n (chá»‰ cho reranker) |
| `scheduler` | Giá»¯ nguyÃªn |
| `dev_ratio` | Giáº£m Ä‘á»ƒ nhiá»u data train

---

## ğŸ”§ Templete Fine-tune

### Template Cháº¡y Fine-tune Embedding

```bash
python fine_tune_bge_m3.py \
  --epochs 5 \
  --batch_size 8 \
  --max_seq_length 384 \
  --evaluation_steps 15 \
  --lr 1e-5 \
  --checkpoint_save_steps 30 \
  --freeze_layers 4 \
  --warmup_steps 100 \
  --resume_from_checkpoint auto
```

### Template Cháº¡y Fine-tune Reranker

```bash
python fine_tune_reranker.py \
  --batch_size 3 \
  --gradient_accumulation_steps 8 \
  --epochs 4 \
  --lr 2e-5 \
  --fp16 \
  --gradient_checkpointing \
  --dev_ratio 0.2 \
  --num_hard_negatives 2 \
  --num_random_negatives 1
```

